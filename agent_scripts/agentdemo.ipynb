{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File** :  demo for LangChain + Gemini\n",
    "\n",
    "**Date** : 6.11.2024\n",
    "\n",
    "**Author** : King Hang, WONG\n",
    "\n",
    "**Description** :\n",
    "\n",
    "Update : Will not use Langchain until online FM deployment. \n",
    "\n",
    "Working towards constructing a RAG system to retrieve UseGalaxy, nextFlow code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split text into chunks: Splitting the text into chunks is a crucial step in building a RAG system. The way you divide the data will directly impact the relevance and accuracy of the retrieved documents for any given query, ultimately determining the quality of the output. Therefore, it is essential to perform semantic splitting, which preserves the meaning of the text within each chunk. This ensures that the chunks are contextually coherent and informative. Below code snippet, will demonstrate how to split the text from a PDF document effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!conda list | grep \"google\" | awk '{print $1}' | xargs -n 1 conda remove -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pypdf2\n",
    "# %pip install tokenizers\n",
    "# %pip install langchain\n",
    "# %pip install transformers\n",
    "# %pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\n",
    "from PyPDF2 import PdfReader\n",
    "from transformers import BertTokenizerFast\n",
    "from langchain_text_splitters.base import TokenTextSplitter\n",
    "\n",
    "local_path = r'C:\\Users\\kingw\\Documents\\Bioplatform\\bioinformatics_platform\\agent_scripts\\CMU writing-research-statement.pdf'\n",
    "\n",
    "pdfreader = PdfReader(local_path)\n",
    "\n",
    "from typing_extensions import Concatenate\n",
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    content = content.replace(\"\\n-\", \"\")\n",
    "    content = content.replace(\"\\n\", \"\")\n",
    "    content = content.replace(\"•\", ' ')\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A research statement is a one to three page document that may be required to apply for an  academic job or (less frequently) graduate school. The purpose of a research statement is to describe the trajectory of your research to a selection/search committee. A research statement allows you to  show that you can take on independent resear ch  demonstrate your writing ability, independence as a r esearcher, and ability to earngrant money state your short-term and long-term resear ch goalsUse the', ' ability to earngrant money state your short-term and long-term resear ch goalsUse the research statement only to describe your research. Your research statement is one of  a number of documents (e.g., personal statement, teaching statement, statement of diversity,  resume/cv, cover letter, etc.) describing your academic career, so be discriminating and strategic about the information you include. Be sure to keep the spotlight on your ideas—not on you as  a person (remember,', ' Be sure to keep the spotlight on your ideas—not on you as  a person (remember, this is not a personal statement).1.Long Term Research AgendaClearly articulate the long-term research agenda that has captured your scholarly interest. This should be included in your introductory paragraph/section. Be sure to emphasize what new  knowledge will be generated for the discipline. Readers are most likely overworked faculty that have limited time to read through countless statements, so get to the bottom line right away.', ' faculty that have limited time to read through countless statements, so get to the bottom line right away.Listed below are some common strategies for articulating your research agenda: a. An explicitly stated long-term goal: “My ultimate goal is to bridge the gap betweenMachine Learning and Bioinformatics.”b. A clearly stated, specific interest in a field/area of research: “My primary academicinterests are developing biologically-inspired approaches to machine learning and, recip', ': “My primary academicinterests are developing biologically-inspired approaches to machine learning and, recip -rocally, to use these approaches to better understand learning in biological systems.”c. A focused statement of a research problem: “Characterizing nonlinear variation in highdimensional data is a challenging problem and it gives the opportunity for statisticians todevelop new methodologies to address it.”2.What’s the story?Demonstrate the trajectory of your research plan,', '”2.What’s the story?Demonstrate the trajectory of your research plan, to include past, current, and future research—with the primary focus on your future. Try to avoid the novice mistake of spending too much time ex -plaining your past experience. Instead, demonstrate your past knowledge and experience by raising intriguing questions and how you plan to explore them in the future. Be sure to include any recogni -tion your work has received—publications, grants, awards', ' Be sure to include any recogni -tion your work has received—publications, grants, awards, etc.—and potential funding sources.Writing A Research StatementWe present three strategies for demonstrating a research plan that focuses on your future research:a. Sequence: Use your dissertation and other major projects to “set the stage” for yourfuture work, making sure to show connections. Consider section headings that relate totime (past, ongoing, future). A temporal organizational scheme highlights your ability', ' headings that relate totime (past, ongoing, future). A temporal organizational scheme highlights your ability toenvision, develop, and accomplish your research goals.b. Novelty: Pr esent your “secret weapon:” what do you have that other researchers don’t?How is your research a game-changer for the field? This approach emphasizes the im-portance of your research in your discipline. It also suggests that you have the ability towork independently,', 'ance of your research in your discipline. It also suggests that you have the ability towork independently, generate funding, and increase the prestige of your department (seethe Novelty Moves handout).c. Problem:  Use the “big problem” + “specific challenge” + “your approach” for each ofyour great research accomplishments. This approach emphasizes the significance ofyour work by describing a problem (for example, an important gap in your field) and thensh', 'your work by describing a problem (for example, an important gap in your field) and thenshowing very explicitly how your approach to the problem fills this gap.3.To tailor or not to tailor? There is a debate in the current literature concerning whether or notyou should tailor your research statement to the specific institution to which you are applying.Example:  My research agenda corresponds well to Stanford’s chemical engineering department, particularly the work of Professor X..While experts rarely say “', '’s chemical engineering department, particularly the work of Professor X..While experts rarely say “don’t tailor!” there are varying degrees of recommendation for  how much tailoring is appropriate (and explicitly how to do it). The best advice we can give: talk to your advisor. 4.Design matters!Visual design can help your reader smoothly navigate your document. Create an inviting and pleasant reading experience for your audience by using: headings to group similar information a bold font', ' inviting and pleasant reading experience for your audience by using: headings to group similar information a bold font to emphasize important points  white space (paragraph breaks, lists, extra space between paragraphs, and adequatemargins) to break the text into manageable chunksDrafting Strategies Give yourself plenty of time (approximately thr ee months) to craft your research statement Get peers and mentors to read your statement Keep your resear ch statement updated like you would a teaching statement']\n"
     ]
    }
   ],
   "source": [
    "max_tokens = 100\n",
    "chunk_overlap = 20\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "splitter = TokenTextSplitter.from_huggingface_tokenizer(tokenizer= tokenizer, chunk_size=max_tokens, chunk_overlap = chunk_overlap)\n",
    "chunks = splitter.split_text(raw_text)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'chunks' (list)\n"
     ]
    }
   ],
   "source": [
    "%store chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing various spellcheckers\n",
    "\n",
    "Conclusion : all are bad\n",
    "\n",
    "1. TextBlob\n",
    "2. NTLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g generate a pale\n"
     ]
    }
   ],
   "source": [
    "# %pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "text = \"g enerate a pple\"\n",
    "blob = TextBlob(text)\n",
    "corrected_text = str(blob.correct())\n",
    "print(corrected_text)  # Likely Output: \"generate apple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate\n",
      "ana\n",
      "apple\n",
      "generate ana apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\kingw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "import nltk \n",
    "nltk.download('words')\n",
    "english_words = set(words.words())\n",
    "\n",
    "def correct_splits(text):\n",
    "    tokens = text.split()\n",
    "    corrected_tokens = []\n",
    "    for i in range(len(tokens) - 1):\n",
    "        combined = tokens[i] + tokens[i+1]\n",
    "        if combined in english_words:\n",
    "            print(combined)\n",
    "            corrected_tokens.append(combined)\n",
    "        else:\n",
    "            # corrected_tokens.append(tokens[i])\n",
    "            pass\n",
    "    # corrected_tokens.append(tokens[-1])  # Add the last word\n",
    "    return ' '.join(corrected_tokens)\n",
    "\n",
    "text = \"g enerate an a pple pie\"\n",
    "corrected_text = correct_splits(text)\n",
    "print(corrected_text)  # Output: \"generate apple\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert into embedding and store in vector db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the text into embeddings & store into a vector database: In this step, we transform each chunk of text into a numerical vector representation, which captures the semantic meaning of the text. These embeddings are then stored in a vector database, which serves as a knowledge repository. This database can be queried to retrieve relevant information based on the semantic similarity of the vectors. Here’s how you can create embeddings and store them in the vector database:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Google Cloud API according to this:  \n",
    "\n",
    "https://cloud.google.com/iam/docs/keys-create-delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to add quota if you see a quota authentication error later on.\n",
    "\n",
    "`gcloud auth application-default set-quota-project ubi-agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=Plvpbo5VCK4O4ecOyFbVytBMliC2AH&access_type=offline&code_challenge=CbPo4M97yHnG0J0eNIMHIjglno5smze0lF3WjWgkuPY&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [C:\\Users\\kingw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\Roaming\\gcloud\\application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "WARNING: You may be running gcloud with a python interpreter installed from Microsoft Store which is not supported by this command. Run `gcloud topic startup` for instructions to select a different python interpreter. Otherwise, you have to set the environment variable `GOOGLE_APPLICATION_CREDENTIALS` to the file path `C:\\Users\\kingw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\Roaming\\gcloud\\application_default_credentials.json`. See https://cloud.google.com/docs/authentication/getting-started#setting_the_environment_variable for more information.\n",
      "WARNING: \n",
      "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get my credentials\n",
    "import os\n",
    "credential_path = r'C:\\Users\\kingw\\Documents\\Bioplatform\\application_default_credentials.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "GoogleGenerativeAIError",
     "evalue": "Error embedding content: 403 Request had insufficient authentication scopes. [reason: \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.ai.generativelanguage.v1beta.GenerativeService.BatchEmbedContents\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\langchain_google_genai\\embeddings.py:227\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[1;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_embed_contents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBatchEmbedContentsRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:1379\u001b[0m, in \u001b[0;36mGenerativeServiceClient.batch_embed_contents\u001b[1;34m(self, request, model, requests, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mPermissionDenied\u001b[0m: 403 Request had insufficient authentication scopes. [reason: \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.ai.generativelanguage.v1beta.GenerativeService.BatchEmbedContents\"\n}\n]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGoogleGenerativeAIError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Typesense\n\u001b[0;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m GoogleGenerativeAIEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/text-embedding-004\u001b[39m\u001b[38;5;124m\"\u001b[39m, task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval_document\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m \u001b[43mTypesense\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypesense_client_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use xxx.a1.typesense.net for Typesense Cloud\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m8108\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use 443 for Typesense Cloud\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotocol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use https for Typesense Cloud\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtypesense_api_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxyz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtypesense_collection_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-with-typesense\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\langchain_community\\vectorstores\\typesense.py:274\u001b[0m, in \u001b[0;36mTypesense.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, typesense_client, typesense_client_params, typesense_collection_name, text_key, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify one of typesense_client or typesense_client_params.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     )\n\u001b[1;32m--> 274\u001b[0m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\langchain_community\\vectorstores\\typesense.py:132\u001b[0m, in \u001b[0;36mTypesense.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run more texts through the embedding and add to the vectorstore.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m \n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypesense\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObjectNotFound\n\u001b[1;32m--> 132\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prep_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39mimport_(docs, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupsert\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\langchain_community\\vectorstores\\typesense.py:96\u001b[0m, in \u001b[0;36mTypesense._prep_texts\u001b[1;34m(self, texts, metadatas, ids)\u001b[0m\n\u001b[0;32m     94\u001b[0m _ids \u001b[38;5;241m=\u001b[39m ids \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts)\n\u001b[0;32m     95\u001b[0m _metadatas: Iterable[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m metadatas \u001b[38;5;129;01mor\u001b[39;00m ({} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts)\n\u001b[1;32m---> 96\u001b[0m embedded_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     98\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: _id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvec\u001b[39m\u001b[38;5;124m\"\u001b[39m: vec, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata}\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _id, vec, text, metadata \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(_ids, embedded_texts, texts, _metadatas)\n\u001b[0;32m    100\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\kingw\\anaconda3\\envs\\bioenv\\lib\\site-packages\\langchain_google_genai\\embeddings.py:231\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[1;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[0;32m    227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbatch_embed_contents(\n\u001b[0;32m    228\u001b[0m             BatchEmbedContentsRequest(requests\u001b[38;5;241m=\u001b[39mrequests, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    229\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GoogleGenerativeAIError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError embedding content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;28mlist\u001b[39m(e\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39membeddings])\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[1;31mGoogleGenerativeAIError\u001b[0m: Error embedding content: 403 Request had insufficient authentication scopes. [reason: \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.ai.generativelanguage.v1beta.GenerativeService.BatchEmbedContents\"\n}\n]"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Typesense\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\", task_type=\"retrieval_document\")\n",
    "\n",
    "docsearch = Typesense.from_texts(\n",
    "    chunks,\n",
    "    embeddings,\n",
    "    typesense_client_params={\n",
    "        \"host\": \"localhost\",  # Use xxx.a1.typesense.net for Typesense Cloud\n",
    "        \"port\": \"8108\",  # Use 443 for Typesense Cloud\n",
    "        \"protocol\": \"http\",  # Use https for Typesense Cloud\n",
    "        \"typesense_api_key\": \"xyz\",\n",
    "        \"typesense_collection_name\": \"gemini-with-typesense\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query relevant documents and pass them to LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini\", convert_system_message_to_human=True)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "question = \"What is Scaled Dot-Product Attention?\"\n",
    "\n",
    "retriever = docsearch.as_retriever()\n",
    "docs = retriever.invoke(question)\n",
    "chain.run(input_documents=docs, question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
